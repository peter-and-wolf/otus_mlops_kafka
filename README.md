# MLOps, №13 "Сбор данных на потоке, Kafka"

## Запуск кластера

`zk-kafka-cluster.yaml` включает:

- "Тренировочный" кластер Kafka из трех брокеров;
- "Тренировочный" кластер Zookeeper из трех нод;
- [Kafka UI](https://docs.kafka-ui.provectus.io/) от provectuslab – web-интерфейс для управления кластером Kafka;
- [ksqldb](https://ksqldb.io/) – специальная база данных, которая умеет работатьс  потоковыми данными из топиков Kafka;
- ksqldb-cli – интерфейс командной строки (консоль) для взаимодействия с ksqldb;

Чтобы все запустить, выполните:

```bash
docker-compose -f zk-kafka-cluster.yaml up
```

## Управление кластером

### Через командную строку

Выполните команду:

```bash
docker exec -it kafka-broker1 bash 
```

Окажетесь "внутри" контейнера, в котором запущен первый брокер Kafka. Теперь можно запускать стандартные утилиты командной строки, предназначеные для управления кластером. 

Например, так:

```bash
kafka-topics --create --topic test --partitions 3 --replication-factor 3 --bootstrap-server kafka1:19092
```
можно создать топик с именем `test`, в котором три партиции, и уровень репликации которого равен трем.

Так:

```bash
kafka-topics --describe --topic test --bootstrap-server kafka1:19092
```

можно вывести на экран информацию о топике `test`.

А так:

```bash
kafka-configs --bootstrap-server kafka1:19092 --alter --entity-type topics --entity-name test --add-config min.insync.replicas=2
```

можно переконфигурировать топик, указав, что параметр `min.insync.replicas` (минимальное количество брокеров, которые должны прислать подтверждение о записи сообщения) теперь равен двум. 

### Через Kafka UI

По адресу `localhost:8282` доступен приятный web-интерфейс, который позволяет выполнять основные операции с кластером чуть комфортнее, чем командная строка. 

## ksqldb

Чтобы попасть в консоль, выполните:

```bash
bash run-ksqldb-shell.sh
```

или

```bash
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
```

Оказавшись в шелле, ksqldb можете исполнять запросы и команды:

Например, создать ksqldb-поток (stream) на соотвествующем топике кафки можно так:

```sql
CREATE STREAM payments (name VARCHAR, amount INTEGER) WITH (KAFKA_TOPIC='payments', VALUE_FORMAT='json', PARTITIONS=3);
```

Поток – абстракция ksqldb, позволяющая читать сообщения из топиков или записывать в них новые сообщения, используя язык, до степени смешения похожий на SQL. Например, когда вы читаете сообщения из  потока, уровнем ниже ksqldb создает Consumer, добавляет его в Consumer-Group, и взаимодействует с топиком Kafka. Тоже самое делали и вы, когда программировали Сonsumer самостоятельно. Разница в том, что с ksqldb не нужно писать Boilerplate-код для работы с Kafkа: просто составляете SQL-like запросы, ksqldb делает остальное.   

> Консьюмеры, которые создает ksqldb, можно увидеть, например, в kafka-ui на вкладке Consumers. 

### Pull-запросы

В общем случае, топики Kafka более динамичные, чем таблицы реляционной базы данны, в топки все время кто-то интенсивно пишет. Поэтому ksqldb вводит два типа запросов. Запросы первого типа ([pull-запросы](https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/select-pull-query/)) похожи на привычные запросы в RDBMS. Например,   


```sql
SELECT * FROM payments;
```

Заберет все данные, которые накопились в потоке (топике) на момент исполнения запроса, и завершится. 

Pull-запросы допускают фильтры, например:

```sql
SELECT * FROM payments WHERE name='Peggy';
```

или 

```sql
SELECT * FROM payments WHERE amount > 900;
```

А вот группировать результаты pull-запросов нельзя. Например, такой запрос 

```sql
SELECT name, SUM(amount) AS total FROM payments GROUP BY name;
```

завершится ошибкой:


<code style="color:tomato">
Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.
Add EMIT CHANGES if you intended to issue a push query.
</code>

### Push-запросы

[Push-запросы](https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/select-push-query/) регистрируют изменения, то есть работают с новыми данными в топике. Продьюсеры, как правило, пишут в топики постоянно и интенсивно, поэтому push-запросы не завершаются сами по себе. Если вы сделали push-запрос SELECT, запускается "вечный" процесс, который непрерывно вычитывает сообщения из топика, обрабатывает их и отдает вам до тех пор, пока вы сами его не завершите. Например, такой запрос:  

```sql
SELECT ROWPARTITION, ROWOFFSET, * FROM payments EMIT CHANGES;

```

будет печатать сообщения из топика в тот момент (практически), когда они в нем появились. Обратите внимание на `ROWPARTITION` и `ROWOFFSET`, которые я запрашиваю вместе с остальными полями стрима, – эти поля ksqldb добавляет в стрим автоматически, они содержат номер партиции и смещение (offset) текущего сообщения. По этим полям можно фильровать, в частности, запрос:

```sql
SELECT ROWPARTITION, ROWOFFSET, * FROM payments WHERE ROWPARTITION=1 EMIT CHANGES;
```

покажет все сообщения, которые падают в первую партицию нашего топика.

В отличие от pull-запросов push-запросы умеют в группировку. Например, 

```sql
SELECT name, COUNT(*) AS cnt, SUM(amount) AS sum FROM payments GROUP BY name EMIT CHANGES;
```

будет группировать результаты по полю `name`, считая количество записей (`COUNT(*) AS cnt`) с соответствующим именем и сумму (`SUM(amount) AS sum`) платежей, поступивших на это имя. Обратите внимание, что значения в колонках `cnt` и `sum` монотонно возрастают. Это работает примерно так: 

* push-запрос запускается (а с ним и соответствующий Консьюмер, можете посмотреть в kafka-ui); 
* заводит в памяти словарь, ключи в котором имена, а значения – счетчик имен и сумма платежей;
* в цикле:
  * выгребает из топика все новые сообщения;
  * комитит их офсеты в Kafka; 
  * увеличивает в словаре соответствующие значения по ключам (именам из пачки сообщений, которые забрал)
  * печатает результаты на экран;

Такая "доагрегация" в единый словарь может быть не очень удобным. Типичный кейс в потоковой обработке – агрегация в скользящем окне. ksqldb может и такое:

```sql
SELECT FROM_UNIXTIME(WINDOWSTART) AS ws, FROM_UNIXTIME(WINDOWEND) AS we, name, COUNT(*) AS cnt, SUM(amount) AS sum FROM payments WINDOW TUMBLING(SIZE 10 SECONDS) GROUP BY name EMIT CHANGES;
```

тут я агрегирую данные в непересекающихся окнах размером 10 секунд (`WINDOW TUMBLING(SIZE 10 SECONDS)`): копим данные 10 секунд, агрегируем, показываем результат. Однако наблюдательный читатель заметит, что вывод данных происходит чаще, чем раз в 10 секунд. Я специально добавил в запрос `FROM_UNIXTIME(WINDOWSTART) AS ws, FROM_UNIXTIME(WINDOWEND) AS we`: `WINDOWSTART` и `WINDOWEND` – поля,которые ksqldb вставляет автоматически, это `Timestamp`-ы начала и конца окна агрегации, а `FROM_UNIXTIME` просто напечатает их в человекочитаемом формате. Вывод у запроса будет примерно такой:

|WS                                  |WE                                  |NAME                                |CNT                                 |SUM                                 |
|------------------------------------|------------------------------------|------------------------------------|------------------------------------|------------------------------------|
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |<span style="color:red">Carol</span>|1                                   |141                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Peggy                               |2                                   |688                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Alice                               |2                                   |918                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Peggy                               |3                                   |907                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Bob                                 |1                                   |941                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Trent                               |1                                   |949                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |<span style="color:red">Carol</span>|2                                   |290                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Bob                                 |2                                   |1043                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Trent                               |2                                   |1823                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |<span style="color:red">Carol</span>|3                                   |1197                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Chuck                               |1                                   |399                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |<span style="color:red">Carol</span>|4                                   |2720                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |<span style="color:red">Carol</span>|5                                   |1478                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Mallory                             |1                                   |912                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Peggy                               |4                                   |1491                                |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Victor                              |1                                   |104                                 |
|2024-10-10T15:11:50.000             |2024-10-10T15:12:00.000             |Trent                               |3                                   |2845                                |
|2024-10-10T15:12:00.000             |2024-10-10T15:12:10.000             |Alice                               |1                                   |832                                 |
|2024-10-10T15:12:00.000             |2024-10-10T15:12:10.000             |Trent                               |1                                   |367                                 |
|             .........              |             .........              |             .........              |             .........              |             .........              |

 Обратите внимание, что имя `Carol` встречается пять раз в течение одного окна, которое началось в `2024-10-10T15:11:50.000` и закончилось `2024-10-10T15:12:00.000`. Это такая особенность push-запросов с клаузой `EMIT CHANGES`, они срабатывают почти сразу, как в топике появляются новые сообщения. Другими словами, за 10 секунд прилетело пять сообщений с именем `Carol`, push-запрос их подхватывал, "доагрегировал" к текущему окну и сразу же печатал результат. 

 Если же вы хотите видеть только конечный результат, когда окно закрывается, замените клаузу `EMIT CHANGES` на `EMIT FINAL`:

```sql
SELECT FROM_UNIXTIME(WINDOWSTART) AS ws, FROM_UNIXTIME(WINDOWEND) AS we, name, COUNT(*) AS cnt, SUM(amount) AS sum FROM payments WINDOW TUMBLING(SIZE 10 SECONDS) GROUP BY name EMIT FINAL;
```

Теперь строчки появляются раз в 10 секунд. За этим наблюдать, если отфильтровать результат по одному имени:

```sql
SELECT FROM_UNIXTIME(WINDOWSTART) AS ws, FROM_UNIXTIME(WINDOWEND) AS we, name, COUNT(*) AS cnt, SUM(amount) AS sum FROM payments WINDOW TUMBLING(SIZE 10 SECONDS) GROUP BY name HAVING name='Carol' EMIT FINAL;
```

Теперь все очевидно, одна строчка раз в 10 секунд:

|WS                                  |WE                                  |NAME                                |CNT                                 |SUM                                 |
|------------------------------------|------------------------------------|------------------------------------|------------------------------------|------------------------------------|
|2024-10-10T15:27:40.000             |2024-10-10T15:27:50.000             |Carol                               |2                                   |1092                                |
|2024-10-10T15:27:50.000             |2024-10-10T15:28:00.000             |Carol                               |3                                   |1846                                |
|2024-10-10T15:28:00.000             |2024-10-10T15:28:10.000             |Carol                               |1                                   |579                                 |
|2024-10-10T15:28:10.000             |2024-10-10T15:28:20.000             |Carol                               |3                                   |1464                                |
|2024-10-10T15:28:20.000             |2024-10-10T15:28:30.000             |Carol                               |5                                   |3183                                |
|2024-10-10T15:28:30.000             |2024-10-10T15:28:40.000             |Carol                               |2                                   |119                                 |
|2024-10-10T15:28:40.000             |2024-10-10T15:28:50.000             |Carol                               |3                                   |1721                                |
|             .........              |             .........              |             .........              |             .........              |             .........              |


### Таблицы

Потоки ksqldb эфемерны, они существуют поверх ваших топиков и позволяют читать и записывать данные. Когда читаете, ksqldb создает Consumer, когда читаете, – Producer, которые живут до тех пор, пока живут соответствующие запросы. Это удобно для оперативной (ad-hoc) аналитики, но если вы хотите хранить результаты ваших запросов подольше, стоит использовать другую абстракцию ksqldb – Таблицы. Создать таблицу можно, например, из результата запроса:

```sql
CREATE TABLE payments_aggr WITH(VALUE_FORMAT='json', KEY_FORMAT='kafka') AS SELECT name, COUNT(*) AS cnt, SUM(amount) AS sum FROM payments WINDOW TUMBLING(SIZE 10 SECONDS) GROUP BY name EMIT FINAL;
```

Теперь можно делать запросы:

```sql
SELECT name, cnt, sum FROM payments_aggr EMIT CHANGES;
```

И самое интересное тут вот что: если вы заглянете в kafka-ui в раздел Topics, вы увидите новый топик `PAYMENTS_AGGR`, в который записываются результаты десятисекундной агрегации по именам.


------

P.S. Спасибо. Живите долго и процветайте!



